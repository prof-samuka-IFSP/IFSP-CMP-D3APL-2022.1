{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09142599-d99c-4b84-ae6b-4ee2abc7df3a",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed1c92-5c77-4898-8cbb-e847af6f72cc",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP) with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb8137-7b1b-42e9-b2e9-75711269596c",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542eb6-d992-499f-9ac6-8771676123c6",
   "metadata": {},
   "source": [
    "#### 1.1 TensorFlow + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab093db2-4853-44eb-b588-da0a71ad6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e36de08-c4c0-4632-af0b-bed7b64296ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde0def4-7b44-4152-92cd-5fac2922825b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f5afb-ecab-48f1-ad12-de12d0c38e40",
   "metadata": {},
   "source": [
    "**GPU available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf10151d-8abe-49f7-a1f2-9f4050d6dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17fb00-de23-48bd-ab8a-1b6cc9089043",
   "metadata": {},
   "source": [
    "### 1.2 Fixing the seed for reproducibility (optional)\n",
    "That's a try for reprodubility in Keras. See more on: <br/>\n",
    "https://machinelearningmastery.com/reproducible-results-neural-networks-keras/ <br/>\n",
    "https://www.tensorflow.org/api_docs/python/tf/random/set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4440090b-9df4-425a-944f-6838e2629149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "seed(42)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3b9b6-207c-4b5a-a243-e68b490c7c1b",
   "metadata": {},
   "source": [
    "#### 1.3 Other imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9377a2-d2d5-4c3b-825a-f389e6091be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231de637-e2aa-4d28-840a-d8c503f63b75",
   "metadata": {},
   "source": [
    "#### 1.4 Loading Fashion MNIST Dataset via Keras\n",
    "https://keras.io/api/datasets/fashion_mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af01078-3198-47ec-913a-6806fd3910b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a052da-0820-4a38-8456-e0508e61cf65",
   "metadata": {},
   "source": [
    "The dataset is already split into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "834d107e-754a-4586-91dd-275e3d8d059c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fashion-mnist', 'mnist.npz']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download done in folder: \"~/.keras/datasets\"\n",
    "import os\n",
    "os.listdir(os.path.expanduser('~/.keras/datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aacde3d-5483-468b-9965-d6800199fef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "\n",
      "X_test.shape: (10000, 28, 28)\n",
      "y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}\\n')\n",
    "\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4680e727-4472-4345-bb20-b9e264112214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20023db2-6b03-4059-9c20-ab3c2c3e9ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1cf3eb2-3952-4bec-bc90-362428e990fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 10\n",
      "Classes: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Classes: {np.unique(y_train).shape[0]}')\n",
    "print(f'Classes: {np.unique(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "445f7cbc-6270-4b4e-ae1f-c46408d5d236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4c8ba7-6842-450f-86e2-99c6669f7b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
    "for ax, image, label in zip(axes, X_train, y_train):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "    ax.set_title(f'Image: {class_names[label]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bfb14c2-e805-48e0-b39a-bca995b85dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. value of X_train: 0\n",
      "Max. value of X_train: 255\n",
      "\n",
      "Min. value of X_test: 0\n",
      "Max. value of X_test: 255\n"
     ]
    }
   ],
   "source": [
    "# 8-bit gray scale\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}\\n')\n",
    "\n",
    "print(f'Min. value of X_test: {X_test.min()}')\n",
    "print(f'Max. value of X_test: {X_test.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fcb542-031b-4f43-a32e-cc095cc1857b",
   "metadata": {},
   "source": [
    "#### 1.5 (Simple) Feature scaling\n",
    "Since we are going to train the neural network using _Gradient Descent_, we must scale the **input features**. For simplicity, we’ll scale the pixel intensities down to the _0–1_ range by dividing them by **255.0** (8-bit gray image):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f955f1b1-3ed9-4dad-a05e-fd8b83e19002",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26ece1f5-7d6a-4406-bd16-6a6d8017cf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min. value of X_train: 0.0\n",
      "Max. value of X_train: 1.0\n",
      "\n",
      "Min. value of X_test: 0.0\n",
      "Max. value of X_test: 1.0\n"
     ]
    }
   ],
   "source": [
    "# rescaled 8-bit gray scale\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}\\n')\n",
    "\n",
    "print(f'Min. value of X_test: {X_test.min()}')\n",
    "print(f'Max. value of X_test: {X_test.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5cd606-7367-4310-883a-81a96a300b8f",
   "metadata": {},
   "source": [
    "#### 1.6 Flattening the images as feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd9be1af-6dd8-442f-a8f6-f5e6c225b160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.shape ==> (n_train_imgs, img_width, img_height)\n",
    "n_train_imgs, img_width, img_height = X_train.shape\n",
    "\n",
    "n_pixels = img_width * img_height\n",
    "n_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c28bcfb7-1192-4a74-86c3-367505594deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test.shape ==> (n_test_imgs, img_width, img_height)\n",
    "n_test_imgs = X_test.shape[0]\n",
    "n_test_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e9e8cee-1986-4f05-afe9-f99c6fd6cb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (n_train_imgs, n_pixels))\n",
    "X_test = np.reshape(X_test, (n_test_imgs, n_pixels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21142047-9cdf-448c-9f62-73ddf35ec812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (60000, 784)\n",
      "X_test.shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed90771-4316-4286-89b7-8bbe077db038",
   "metadata": {},
   "source": [
    "## 2. Building and Training a MLP via Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692f75c8-57b8-4d7f-914b-1369e60cdb19",
   "metadata": {},
   "source": [
    "### 2.1 Defining the Network Architecture\n",
    "Proposed architecture for Multiclass Classification:\n",
    "- Input Layer: 784 neurons (number of pixels)\n",
    "- Hidden Layer 1: 256 neurons, ReLu\n",
    "- Hidden Layer 2: 128 neurons, ReLu\n",
    "- Output Layer: 10 neurons, Softmax\n",
    "\n",
    "In short: [784], [256 ReLU, 128 ReLU], [10 Softmax] ==> pyramid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9ced7-ea7e-4fac-bd1c-bc82851067a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **Defining the Network's Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a0e0365-17ee-40cf-8fa0-ae1a39590aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "# InputLayer: https://www.tensorflow.org/api_docs/python/tf/keras/layers/InputLayer\n",
    "# Dense: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "\n",
    "### Default weight and bias initialization:\n",
    "# kernel_initializer='glorot_uniform',\n",
    "# bias_initializer='zeros',\n",
    "\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(n_pixels,)))  # InputLayer will be ignored in the .summary() method.\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e3d2de-bb3b-4121-b787-a5c322d6e26f",
   "metadata": {},
   "source": [
    "##### **Summarizing Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc0e7573-0ad0-4837-844b-bb5871ac6955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e4594-d1ed-4f73-8eac-39ea9ca4b6ab",
   "metadata": {},
   "source": [
    "##### **Creating a Model (archicture) from a list of Layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ec41448-55f5-4261-bde7-5e886f69abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    layers=[\n",
    "        InputLayer(input_shape=(n_pixels,)),\n",
    "        Dense(300, activation='relu'),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5987f9c-e5c0-40f4-b21f-9c49ce069445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70519ce0-edd7-46ed-b366-622031cd0c49",
   "metadata": {},
   "source": [
    "##### **Named Layers (without spaces)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ff40b8a-dede-4a4e-9918-f45319e03d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, we can define names for each layer and for the model\n",
    "model = Sequential(name='MyMLP')\n",
    "model.add(InputLayer(input_shape=(n_pixels,), name='Input'))  # InputLayer will be ignored in the .summary() method.\n",
    "model.add(Dense(300, activation='relu', name='Hidden_1'))\n",
    "model.add(Dense(100, activation='relu', name='Hidden_2'))\n",
    "model.add(Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c17a4f68-0316-4aed-adb6-98a7c6ec0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MyMLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden_1 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " Hidden_2 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " Output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68223f6-3dca-4971-8ba0-eb326f9af7de",
   "metadata": {},
   "source": [
    "### 2.2 Info about the Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e945e5f-dbbe-47d8-9202-070edfa1fef4",
   "metadata": {},
   "source": [
    "#### **List of layers (except the input layer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e39afb-60ff-4e44-8919-a7e70dc2c9e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae3c1ab-59a9-4cfb-8cd4-797022786705",
   "metadata": {},
   "source": [
    "#### **Getting a specific layer**\n",
    "\n",
    "According to our convention:\n",
    "- Layer 1: Input Layer\n",
    "- Layer 2: Hidden Layer 1\n",
    "- Layer 3: Hidden Layer 2\n",
    "- Layer 4: Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4bd52e-4135-4b28-96d7-e1a81939cad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100195ce-c8c5-4ace-929d-4a40ee706fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aeafd2-24e3-48b3-b8e6-b01343c272e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f70244-472e-4ba1-af9e-2fd385071de5",
   "metadata": {},
   "source": [
    "#### **Accessing the weights and biases of a layer**\n",
    "\n",
    "PS: While the model is not trained, the layer's weights and biases come from the initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36572ec-6f87-4b9f-b461-07e7dbd9b8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7bbd5f-bf79-40f9-ae53-88c4ce01e9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa1cc6e-a33b-4d68-bb71-d1ad125a9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hidden 1')\n",
    "print(f'weights.shape = {weights.shape}')\n",
    "print(f'biases.shape = {biases.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7e91f-b454-45b5-98ec-024e78fdbce3",
   "metadata": {},
   "source": [
    "**PS:** Note that the **Weight Matrix's shape** has a different _order/convention_ from what we have seen so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf61d6-6ab5-4686-9a0c-a01e4e8cfd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a442348a-bb0b-4d93-95bb-6b1a2df7899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828eedc-3c42-4325-9316-acb57846c31b",
   "metadata": {},
   "source": [
    "#### **There are other getters (`get_`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657d5be-3f4d-4ebc-a5b2-82736cd6ec23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5bfae-3e4d-4fce-a4da-d68b0bb6b20b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3170f-93d2-4d8c-9272-7bd903432027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882bc9a2-a08d-455a-9d1d-cfa0299e50f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a41bc-b724-46ae-afb3-43f0195cac4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb73252c-8789-449f-8ef9-0bb4f3f629ef",
   "metadata": {},
   "source": [
    "**PS:** There are the corresponding setter methods (`set_`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85c983-328c-4c21-aaf2-c7feb5bfe523",
   "metadata": {},
   "source": [
    "### 2.2 Compiling: Defining the Loss Function, Optimizer, and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be8c98-8dc9-4957-ba6c-a81c90801acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation: https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5bccb8-dc2e-4890-91ea-8716d90509a0",
   "metadata": {},
   "source": [
    "#### **Loss:**\n",
    "\n",
    "We use the `\"sparse_categorical_crossentropy\"` loss because we have **sparse labels** (i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are **exclusive**.\n",
    "\n",
    "If instead we had _one target probability per class_ for each instance (such as one-hot vectors, e.g. [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.] to represent class 3), then we would need to use the `\"categorical_crossentropy\"` loss instead.\n",
    "\n",
    "If we were doing **binary classification** (with one or more binary labels), then we would use the `\"sigmoid\"` _activation function_ in the **output layer**, and we would use the `\"binary_crossentropy\"` loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2e1113-6b17-4114-9187-4486660f6f57",
   "metadata": {},
   "source": [
    "#### **Optimizer:**\n",
    "\n",
    "`\"sgd\"` means that we will train the model using simple **Stochastic Gradient Descent** with its default values (see https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD).<br/>\n",
    "To change some default value, for example the _learning rate_, use `optimizer=keras.optimizers.SGD(lr=???)`.\n",
    "\n",
    "There are other otimizers available in Keras: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e89eaf-3b3a-4f2c-96e5-93c2b17e4bda",
   "metadata": {},
   "source": [
    "#### **Metrics:**\n",
    "List of _metrics_ to be evaluated by the model during **training** and **testing**. <br/>\n",
    "Each of this can be a _string_ (name of a built-in function), _function_ or a `tf.keras.metrics.Metric` instance: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "\n",
    "**PS:** By default, _F1 score_ **is not** part of keras metrics. To use it, we need to create our own function and pass it to `metrics`: https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d#:~:text=By%20default%2C%20f1%20score%20is,like%20accuracy%2C%20categorical%20accuracy%20etc. <br/>\n",
    "Other option is to use [**TensorFlow Addons**](https://www.tensorflow.org/addons) that provides several additional functionalities to TensorFlow, such as [**F1 Score**](https://www.tensorflow.org/addons/api_docs/python/tfa/metrics/F1Score): https://stackoverflow.com/a/71705026/7069696\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1b6ce-3283-46ee-83d1-cce66271eddb",
   "metadata": {},
   "source": [
    "### 2.4 Training\n",
    "\n",
    "In case of GPU drivers, we can monitor its use by [_gpustat_](https://github.com/wookayin/gpustat).\n",
    "\n",
    "On terminal, use: `gpustat -cpi`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8580290-0b32-43ac-a33d-735d11c6682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b311b54-6803-4d99-9533-4415a738ca72",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "We are using a _validation set_ during training by the argument `validation_split`: https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/ParameterServerStrategy\n",
    " <br/>\n",
    "For example, `validation_split=0.2` tells Keras to use **the last** 20% of the data (before shuffling) for **validation**. <br/>\n",
    "\n",
    "Additionally, the argument `validation_batch_size` tells the number of samples per **validation batch**. If _unspecified_, will default to `batch_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c619e00b-fa9a-4748-984a-951604f27f25",
   "metadata": {},
   "source": [
    "#### **Checking the training history object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e5bd5f-c1a2-44cf-beca-63e17d1155e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234f8c7-2b90-4ed4-a211-216e5a775b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3f270-0c8e-4496-91d7-f03602615e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99160eef-e499-454f-8d74-017ce2614931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f7dc519-947b-492a-bf99-c6638cf75338",
   "metadata": {},
   "source": [
    "#### **Visualizing the training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb091e-a508-4a5b-9efa-6da9d1b47b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69952b3-0c62-48ed-9257-ed851d6b828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df.plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a66ed4-74aa-4aa3-9e88-13fb86b5314d",
   "metadata": {},
   "source": [
    "The _training set_ performance ends up beating the _validation performance_, as is generally the case when you train for long enough. <br/>\n",
    "You can tell that the model _has not quite converged yet_, as the _validation loss_ is still (or could be) going down, so you should probably\n",
    "**continue training**.\n",
    "\n",
    "It’s as simple as calling the `fit()` method again, since Keras **_just_ continues training where it left off**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df728186-8b63-491d-a5fd-ca621abb1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d0566-f020-4c21-9f6c-7044816cce36",
   "metadata": {},
   "source": [
    "Note that our _training loss_ is lower than that from the last epoch in the previous training. This confirms that our `fit()` method **continues training** where it left off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9171e0-dd03-4626-8294-6d5083b46782",
   "metadata": {},
   "source": [
    "#### **More about training in Keras**\n",
    "Extracted from \"A. Géron, Hands-on Machine Learning (Chapter 10)\".\n",
    "\n",
    "If the training set was _very skewed_, with some classes being _overrepresented_ and others _underrepresented_, it would be useful to set the `class_weight` argument when calling the `fit()` method, which would give a **larger weight** to _underrepresented classes_ and a **lower weight** to _overrepresented classes_. These weights would be used by Keras when _computing the loss_.\n",
    "\n",
    "If you need _per-instance weights_, set the `sample_weight` argument (if both `class_weight` and `sample_weight` are provided, Keras **multiplies them**).\n",
    "\n",
    "_Per-instance weights_ could be useful if some instances were labeled by _experts_ while others were labeled using a _crowdsourcing platform_: you might want to give more weight to the former."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378c5f15-1de7-45d0-8c4f-11db59aea0cf",
   "metadata": {},
   "source": [
    "#### **Saving a Model**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e439e-b0b2-451b-872c-948c31fa0062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d249a00-df74-41b1-b4bb-d764fda7f3e7",
   "metadata": {},
   "source": [
    "See also:\n",
    "- `save_spec`: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save_spec\n",
    "- `save_weights`: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#save_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd5fde8-f84f-469d-a5b7-6b879ea24c16",
   "metadata": {},
   "source": [
    "#### **Loading a Model**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#example_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a1a710-472a-45bd-842d-845e06c0ae5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1ae69-28aa-437c-bb94-66b5ea5e2bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52717e71-8aa2-4fd1-b25a-e35e73ab9c5a",
   "metadata": {},
   "source": [
    "See also:\n",
    "- `load_weights`: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#load_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ca1cb-20b5-439b-8240-e511abb305c7",
   "metadata": {},
   "source": [
    "### 2.5 Evaluating and Predicting New Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db26d3c-46e9-437a-a448-4adf4542958a",
   "metadata": {},
   "source": [
    "#### **Evaluation**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a75d26-ca65-405e-85bf-377a035a82a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e0efd4-0647-435c-a57d-c4d617913992",
   "metadata": {},
   "source": [
    "#### **Prediction**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739ea39-55a6-47c9-a5ae-e8d3e41e6230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "601d558a-9208-4bb3-bde4-67b1c23bc54c",
   "metadata": {},
   "source": [
    "#### **Class Prediction**\n",
    "https://stackoverflow.com/a/69503180/7069696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c320-b6c1-4c7f-b859-522e65d5f272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd684-66be-4eb8-9a1d-798408e95a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a7db-b0f5-4638-a074-1134538ad1b5",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7ec6-30c1-4285-a43e-1dbef982d66f",
   "metadata": {},
   "source": [
    "Repeat all steps shown in this notebook for the MNIST dataset available in Keras: <br/>\n",
    "https://keras.io/api/datasets/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99933cce-de11-4828-96b1-efdd7d67b9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
