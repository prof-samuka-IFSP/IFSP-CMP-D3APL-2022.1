{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09142599-d99c-4b84-ae6b-4ee2abc7df3a",
   "metadata": {},
   "source": [
    "**D3APL: Aplicações em Ciência de Dados** <br/>\n",
    "IFSP Campinas\n",
    "\n",
    "Prof. Dr. Samuel Martins (Samuka) <br/><br/>\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed1c92-5c77-4898-8cbb-e847af6f72cc",
   "metadata": {},
   "source": [
    "# Animal Dataset - v1\n",
    "We will evaluate some **multiclass classification** CNNs to predict the classes of the **Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10\n",
    "\n",
    "\n",
    "Target goals:\n",
    "- Proposed CNN's Architecture\n",
    "- Dataset Preprocessing\n",
    "    + Import the image data\n",
    "    + Preprocessing the data\n",
    "        - Image rescaling\n",
    "        - Normalization\n",
    "    + Save the preprocessed data\n",
    "    + Convert the images into a _feature matrix (X)_ and a list of _target labels (y)_\n",
    "- Train CNN\n",
    "    - Use early stopping regularization\n",
    "- Evaluate a simple CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb8137-7b1b-42e9-b2e9-75711269596c",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3542eb6-d992-499f-9ac6-8771676123c6",
   "metadata": {},
   "source": [
    "#### 1.1 TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab093db2-4853-44eb-b588-da0a71ad6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36de08-c4c0-4632-af0b-bed7b64296ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f5afb-ecab-48f1-ad12-de12d0c38e40",
   "metadata": {},
   "source": [
    "**GPU available?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf10151d-8abe-49f7-a1f2-9f4050d6dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17fb00-de23-48bd-ab8a-1b6cc9089043",
   "metadata": {},
   "source": [
    "### 1.2 Fixing the seed for reproducibility (optional)\n",
    "That's a try for reprodubility in Keras. See more on:\n",
    "- https://stackoverflow.com/a/59076062\n",
    "- https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41809176-c43b-4143-940e-e63e26394fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def reset_random_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    \n",
    "# make some random data\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25efbd0-4d14-4f97-84f7-18e6e103a6b9",
   "metadata": {},
   "source": [
    "### 1.3. Dataset\n",
    "**Animal Dataset**: https://www.kaggle.com/datasets/alessiocorrado99/animals10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61214708-7ce5-4b91-9a2d-86acbd3eef02",
   "metadata": {},
   "source": [
    "#### 1.3.1 Load the dataset\n",
    "**Balanced dataset**: _'../datasets/animal-dataset/animals_dataset_balanced.csv'_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf64ef0-0c66-47c6-9233-0e8f61fd0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba804a2-aa9f-46a2-83bb-39c82ed01fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('../datasets/animals-dataset/animals_dataset_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34e3e7-6599-4df5-a4f2-253a61579794",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e324b-4a1d-48ae-9458-96ea4a7290ff",
   "metadata": {},
   "source": [
    "#### 1.3.2 Dataset Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdfb469-da26-4165-99d5-c0267d9f3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(dataset_df[\"class\"].unique())\n",
    "n_classes = len(class_names)\n",
    "\n",
    "print(f'Number of classes: {n_classes}')\n",
    "print(f'Classes: {class_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b17035-7d19-4456-b16f-2ea07c87b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples per class\n",
    "dataset_df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab1866-1216-42b0-b609-13ff1f02c41c",
   "metadata": {},
   "source": [
    "### 1.4. Split the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b5a808-8341-486d-b1fd-d54458d0edb9",
   "metadata": {},
   "source": [
    "Since we will _preprocess the images_, we would like to _keep the pathname_ for the **original images** just in case of recovering them. <br/>\n",
    "Therefore, we will split the dataset directly from the `Pandas DataFrame`.\n",
    "\n",
    "We will also defined a _fixed validation set_ for comparison purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc9ae8-028b-4d4b-b26a-a637a201a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for a stratified sampling, we need to pass the labels\n",
    "labels = dataset_df['class']\n",
    "\n",
    "dataset_df_full_train, dataset_df_test = train_test_split(dataset_df, test_size=0.2, random_state=42, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b56bf89-0fe9-4672-a483-8b2c3eeaaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a stratified sampling, we need to pass the labels\n",
    "labels_full_train = dataset_df_full_train['class']\n",
    "\n",
    "dataset_df_train, dataset_df_val = train_test_split(dataset_df_full_train, train_size=0.8, random_state=42, stratify=labels_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c4dbc-0d7e-48d5-af97-60e95546dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class balancing in the training set\n",
    "dataset_df_train['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a947bf-d6dc-4f2e-80d2-f901e5222e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class balancing in the validation set\n",
    "dataset_df_val['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0381dcaa-6914-42f2-b9e9-3ef42e70cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking class balancing in the training set\n",
    "dataset_df_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cac26-25c1-467a-a446-4910a9512320",
   "metadata": {},
   "source": [
    "## 2. Building and Training a CNN via Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a474b87c-b0d8-4079-a16d-5dc72ebf5135",
   "metadata": {},
   "source": [
    "### 2.1 Defining the Network Architecture\n",
    "That's a simple CNN for _Multiclass Classification_:\n",
    "- **INPUT [64x64x3]**\n",
    "- CONV [32, 4x4x3, 'valid']\n",
    "- RELU\n",
    "- MAX_POOL [2x2, stride=(1,1)]\n",
    "- CONV [32, 4x4x3, 'valid']\n",
    "- RELU\n",
    "- MAX_POOL [2x2, stride=(1,1)]\n",
    "- FLATTEN\n",
    "- FC [256]\n",
    "- RELU\n",
    "- FC [10, 'softmax']  # number of classes\n",
    "\n",
    "- optimizer: SGD with `learning_rate=0.01`\n",
    "- kernel_initializer: \"glorot_uniform\"\n",
    "- bias_initializer: \"zeros\"\n",
    "- **Early stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31de318-1b03-4bf1-81e4-addb3b059e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "def build_cnn(input_shape, n_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(4,4), input_shape=input_shape, activation='relu'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "        Conv2D(filters=32, kernel_size=(4,4), activation='relu'),\n",
    "        MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(256, activation='relu'),\n",
    "        Dense(n_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d877603-c3b1-4053-854a-7def148cf2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (64, 64, 3)\n",
    "\n",
    "model = build_cnn(input_shape, n_classes)\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017e44a-1cac-4000-b651-4e137f4d87ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430a83e6-1a7a-4d73-9c47-149f6e18ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "# vertical\n",
    "plot_model(model, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2bc705-b54e-438d-b246-f8fe52501c8a",
   "metadata": {},
   "source": [
    "### 2.2 Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af1e3dd-5b2b-4d8f-92aa-fcfabadbf216",
   "metadata": {},
   "source": [
    "- **Image Resizing**\n",
    "    + Since the **input layer's shape** and the **images' shape** ***are different***, we need to **resize** the images to the **input layer's shape**.\n",
    "    + Let's use the function `c2.resize()` for that: https://learnopencv.com/image-resizing-with-opencv/#resize-by-wdith-height\n",
    "- **Intensity (feature) Scaling**\n",
    "    + Animals dataset contain 24-bit color images, i.e., it is a color image where each channel is a 8-bit grayscale image (values from 0 to 255)\n",
    "    + We will simply rescale the values to [0, 1] by dividing them by 255.\n",
    "- **Label Encoder**\n",
    "    + Encode the string classes into class integers from 0 to n_classes-1\n",
    "    + https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "    \n",
    "Create a function that performs all these steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8d6c2-a7de-4205-933c-053731e5156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "def preprocess_animals_dataset(dataset_df, label_encoder: LabelEncoder, new_dims=(64, 64)):\n",
    "    # load the images as a feature matrix\n",
    "    image_list = []  # list of numpy arrays\n",
    "    \n",
    "    for index, img_path in enumerate(dataset_df['image_pathname']):\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # image resizing\n",
    "        # for gray or color images, the linear interpolation sounds good\n",
    "        img = cv2.resize(img, new_dims, interpolation=cv2.INTER_LINEAR)        \n",
    "        image_list.append(img)\n",
    "        \n",
    "        # verbose - print every 1000 iterations\n",
    "        if index % 1000 == 0:\n",
    "            print(f'{index + 1}/{dataset_df.shape[0]} - {img_path}')\n",
    "    \n",
    "    X = np.array(image_list)\n",
    "    \n",
    "    # feature scaling\n",
    "    X = X / 255.0\n",
    "    \n",
    "    # encoding the classes\n",
    "    y = label_encoder.fit_transform(dataset_df['class'])\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddc21a-6483-445e-a8d1-3d57fbe6e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Label Encoder from the train set\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(dataset_df_train['class'])\n",
    "\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86694d34-dd62-47ee-8d44-09e7f23b5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the train set\n",
    "X_train, y_train = preprocess_animals_dataset(dataset_df_train, label_encoder, new_dims=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da977ea-5942-4bed-918d-4b591113c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train (classes): {np.unique(y_train)}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "\n",
    "# rescaled 24-bit color image\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0c5f8-18cb-4bec-896b-585a5c77e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7da11-3d64-488b-8a4f-efe34a27127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the validation set\n",
    "X_val, y_val = preprocess_animals_dataset(dataset_df_val, label_encoder, new_dims=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413ad72-5c72-4bb7-8178-8cb990435041",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_val.shape: {X_val.shape}')\n",
    "print(f'y_val (classes): {np.unique(y_val)}')\n",
    "print(f'y_val.shape: {y_val.shape}')\n",
    "\n",
    "# rescaled 24-bit color image\n",
    "print(f'Min. value of X_val: {X_val.min()}')\n",
    "print(f'Max. value of X_val: {X_val.max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36abf9-4370-40af-a2e6-a1213851f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72af4c8-75c2-4df0-891d-000dfb1c44ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the test set\n",
    "X_test, y_test = preprocess_animals_dataset(dataset_df_test, label_encoder, new_dims=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02adf81b-170a-44f5-95ee-19e4909b0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_test (classes): {np.unique(y_test)}')\n",
    "print(f'y_test.shape: {y_test.shape}')\n",
    "\n",
    "# rescaled 24-bit color image\n",
    "print(f'Min. value of X_test: {X_test.min()}')\n",
    "print(f'Max. value of X_test: {X_test.max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c4b450-bfa7-476d-babe-d184078fa1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e582c-bed7-4dcb-ba89-1fee1c85ae91",
   "metadata": {},
   "source": [
    "Since this function may be useful in other notebooks, let's create a **python file/module** to make it available:\n",
    "\n",
    "**File:** `animals_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaf259c-d4a5-4892-acde-722f5bcf147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import animals_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb1882-495b-47f9-bc89-cd2553fcfc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing the train set\n",
    "X_train, y_train = animals_utils.preprocess_animals_dataset(dataset_df_train, label_encoder, new_dims=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7488d0-7337-4f30-94cd-c139faa90e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'y_train (classes): {np.unique(y_train)}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "\n",
    "# rescaled 24-bit color image\n",
    "print(f'Min. value of X_train: {X_train.min()}')\n",
    "print(f'Max. value of X_train: {X_train.max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd75d04-deb8-49e1-9a69-cd24b40a1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea86c72-0206-4f5c-9e99-3564d91230d6",
   "metadata": {},
   "source": [
    "#### **Observation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cd408-9b70-4464-92b9-28dcd33797ef",
   "metadata": {},
   "source": [
    "While _image resizing_ and _feature scaling_ **don't learn** any parameter, our _label encoding_ learns the convertion between _class names_ to _sequential integers_ considering the **entire data**. <br/>\n",
    "To consider a _real scenario_, we shouldn't do that. We should _split the data_ into _training and testing sets_ ***before* applying any preprocessing** to avoid _snooping bias_. <br/>\n",
    "\n",
    "One better way is to create a **Scikit-learn `Pipeline`** to _preprocess our data_. For that, we would have to create a _custom sklearn transformer_ to resize the images as well as for the simple feature normalization, and label encoding. Then, we could use this **preprocessing step** in production to preprocess any data!\n",
    "\n",
    "Another way is consider the _preprocessing steps_ as **layers** from your Neural Network: https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978509d1-32f1-4531-a4d0-18d08459de9a",
   "metadata": {},
   "source": [
    "### 2.3 Save the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fdfc9-23f3-479e-9f3b-d3b69d07872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "out_dir = '../datasets/animals-dataset/preprocessed'\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "    \n",
    "dataset_df_full_train.to_csv(os.path.join(out_dir, 'full_train.csv'), index=False)\n",
    "\n",
    "dataset_df_train.to_csv(os.path.join(out_dir, 'train.csv'), index=False)\n",
    "np.save(os.path.join(out_dir, 'train_data_64x64x3.npy'), X_train)\n",
    "np.save(os.path.join(out_dir, 'train_labels.npy'), y_train)\n",
    "\n",
    "dataset_df_val.to_csv(os.path.join(out_dir, 'validation.csv'), index=False)\n",
    "np.save(os.path.join(out_dir, 'validation_data_64x64x3.npy'), X_val)\n",
    "np.save(os.path.join(out_dir, 'validation_labels.npy'), y_val)\n",
    "\n",
    "dataset_df_test.to_csv(os.path.join(out_dir, 'test.csv'), index=False)\n",
    "np.save(os.path.join(out_dir, 'test_data_64x64x3.npy'), X_test)\n",
    "np.save(os.path.join(out_dir, 'test_labels.npy'), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1b6ce-3283-46ee-83d1-cce66271eddb",
   "metadata": {},
   "source": [
    "### 2.5 Training with Early Stopping\n",
    "\n",
    "In case of GPU drivers, we can monitor its use by [_gpustat_](https://github.com/wookayin/gpustat).\n",
    "\n",
    "On terminal, use: `gpustat -cpi`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a378a5ad-de87-4ecd-b738-19a37dc89ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6649b19-d39a-4ede-af51-911181ad0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7dc519-947b-492a-bf99-c6638cf75338",
   "metadata": {},
   "source": [
    "#### **Visualizing the training history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb091e-a508-4a5b-9efa-6da9d1b47b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69952b3-0c62-48ed-9257-ed851d6b828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[['loss', 'val_loss']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xticks(range(30))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')\n",
    "\n",
    "history_df[['accuracy', 'val_accuracy']].plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.xticks(range(30))\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc4b9d-d057-4a3d-9b87-142290632c4a",
   "metadata": {},
   "source": [
    "## 3. Evaluating and Predicting New Samples by using our Overfitted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114493b-379d-4407-8f3f-278806a9c9fb",
   "metadata": {},
   "source": [
    "#### **Evaluation**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a75d26-ca65-405e-85bf-377a035a82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c74cf-ba92-40a3-9bba-728e893a58a8",
   "metadata": {},
   "source": [
    "#### **Prediction**\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739ea39-55a6-47c9-a5ae-e8d3e41e6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba = model.predict(X_test)\n",
    "y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea9d666-911d-41e9-9954-f7b844deb99a",
   "metadata": {},
   "source": [
    "#### **Class Prediction**\n",
    "https://stackoverflow.com/a/69503180/7069696"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887c320-b6c1-4c7f-b859-522e65d5f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(y_test_proba, axis=1)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dd684-66be-4eb8-9a1d-798408e95a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "print(classification_report(y_test, y_test_pred, target_names=[name for name in class_names]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafc6b3-a9c5-4d6f-972f-4796208ca8de",
   "metadata": {},
   "source": [
    "We got a **poor accuracy** of XXXX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af86de17-0a7a-4de8-b939-6f427e3e5cc7",
   "metadata": {},
   "source": [
    "#### **Visualizing some misclassified image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc18cd2-0ae2-405a-a828-ae88bb24a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_class_name = label_encoder.inverse_transform(y_test)\n",
    "y_test_pred_class_name = label_encoder.inverse_transform(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655f83c-da66-48e6-b132-483808b1ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_mask = y_test_class_name != y_test_pred_class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00197021-3dab-4282-b5b9-ec466a103268",
   "metadata": {},
   "source": [
    "**Sheep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedb5ef-c811-4524-a76e-671654ae0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheep_error_mask = misclassification_mask & (y_test_class_name == \"sheep\")\n",
    "\n",
    "np.argwhere(sheep_error_mask)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be74abc7-8c28-4069-833c-94d067248be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 21\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c46cec-21a6-4463-9a8f-431bd382b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251e55f-7309-4e7c-aadb-cb4e15717059",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 24\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b17abe-1eaf-461c-aa4f-e516b8e4fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc08df-eaa6-41fe-8f73-bff73495cc56",
   "metadata": {},
   "source": [
    "**Dog**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8239921-7753-41b7-803c-b7d6cd20c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_error_mask = misclassification_mask & (y_test_class_name == \"dog\")\n",
    "\n",
    "np.argwhere(dog_error_mask)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a89b2b-018e-4a67-ac7f-01ee8e4496c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 0\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827baad-da63-49d0-8b5b-5640abfba9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c97d6c-b1a3-42da-ada0-5e02ac683fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_idx = 13\n",
    "\n",
    "plt.imshow(X_test[img_idx])\n",
    "plt.title(f'True: {y_test_class_name[img_idx]}, Predicted: {y_test_pred_class_name[img_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4a0ab-471e-4224-a6b4-c524e95ed788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original image\n",
    "img_path = dataset_df_test.iloc[img_idx]['image_pathname']\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a3a7db-b0f5-4638-a074-1134538ad1b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee7ec6-30c1-4285-a43e-1dbef982d66f",
   "metadata": {},
   "source": [
    "Repeat the experiments considering different:\n",
    "-  values for _learning_rate_ of SGD\n",
    "- optimizers (e.g., 'nadam')\n",
    "- kernel regularizer (e.g., 'l2')\n",
    "- Dropout regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
